# AI Virtual Classroom - Dual Teacher System

An intelligent educational platform featuring **two AI teacher avatars** that work together in real-time to teach and explain content from any website. The system uses advanced AI to generate natural speech, lip-synced video animations, and contextual responses based on the content students are viewing.

## ğŸ¯ What This Project Does

**The Problem**: Traditional online learning lacks the personal, interactive experience of a real classroom with multiple teachers.

**The Solution**: Two AI teachers that:
- **Read and understand** any website content the student is viewing
- **Take turns** speaking (one teaches while the other prepares the next response)
- **Generate natural speech** with realistic lip-sync animation
- **Provide contextual explanations** based on the specific content visible on screen
- **Support multiple languages** for global accessibility

**The Experience**: Students browse any website while two AI teachers watch, understand, and explain the content in real-time through natural conversation.

---

## ğŸ—ï¸ System Architecture

### High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Student Browser                        â”‚
â”‚  â€¢ Views website content                                        â”‚
â”‚  â€¢ Sees two AI teachers side-by-side                           â”‚
â”‚  â€¢ Receives real-time explanations                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP/SSE Events
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (Streamlit)                         â”‚
â”‚  Port: 8501                                                      â”‚
â”‚  â€¢ Dual video players (Left & Right teachers)                   â”‚
â”‚  â€¢ Website iframe                                                â”‚
â”‚  â€¢ Chat interface                                                â”‚
â”‚  â€¢ Language selector                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP Requests
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Coordinator API (FastAPI)                          â”‚
â”‚  Port: 8004                                                      â”‚
â”‚  â€¢ Session state management                                     â”‚
â”‚  â€¢ Turn-taking logic (who speaks next)                          â”‚
â”‚  â€¢ Event streaming (SSE) to frontend                          â”‚
â”‚  â€¢ Job queue management                                          â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                           â”‚
      â†“                                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   n8n Workflows     â”‚              â”‚   n8n Workflows     â”‚
â”‚   (Orchestration)   â”‚              â”‚   (Orchestration)   â”‚
â”‚   Port: 5678        â”‚              â”‚   Port: 5678        â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                    â”‚
      â”‚ Left Worker Pipeline              â”‚ Right Worker Pipeline
      â”‚                                    â”‚
      â”œâ”€â†’ Get Session State               â”œâ”€â†’ Get Session State
      â”œâ”€â†’ LLM (Ollama)                    â”œâ”€â†’ LLM (Ollama)
      â”œâ”€â†’ Map Language to Voice          â”œâ”€â†’ Map Language to Voice
      â”œâ”€â†’ TTS (Piper)                     â”œâ”€â†’ TTS (Piper)
      â”œâ”€â†’ Video (LongCat-Video)          â”œâ”€â†’ Video (LongCat-Video)
      â””â”€â†’ Notify Coordinator              â””â”€â†’ Notify Coordinator
```

### Component Details

| Component | Port | Purpose | Technology |
|-----------|------|---------|------------|
| **Frontend** | 8501 | User interface with dual teachers | Streamlit |
| **Coordinator API** | 8004 | Session state & turn-taking | FastAPI |
| **n8n** | 5678 | Workflow orchestration | n8n (Node.js) |
| **Ollama** | 11434 | LLM inference (Mistral 7B) | Ollama |
| **TTS Service** | 8001 | Text-to-speech generation | Piper TTS |
| **Animation Service** | 8002 | Video animation (placeholder) | - |
| **LongCat-Video** | 8003 | Lip-sync video generation | LongCat-Video |
| **PostgreSQL** | 5432 | Database + vector search | PostgreSQL + pgvector |

---

## ğŸ“Š Data Flow Logic Tree

### Complete Request Flow

```
Student Action (Scroll/Click)
    â”‚
    â”œâ”€â†’ Frontend captures: URL + visible text + scroll position
    â”‚
    â”œâ”€â†’ POST /session/{id}/section
    â”‚   â””â”€â†’ Coordinator stores snapshot
    â”‚
    â”œâ”€â†’ Coordinator determines: Which teacher should respond?
    â”‚   â”œâ”€â†’ Check current turn (left/right)
    â”‚   â”œâ”€â†’ Check if other teacher is ready
    â”‚   â””â”€â†’ Enqueue render job
    â”‚
    â”œâ”€â†’ n8n Worker receives job
    â”‚   â”‚
    â”‚   â”œâ”€â†’ Step 1: Get Session State
    â”‚   â”‚   â””â”€â†’ GET /session/{id}/state
    â”‚   â”‚
    â”‚   â”œâ”€â†’ Step 2: Extract Payload
    â”‚   â”‚   â””â”€â†’ Parse: sectionPayload, language, teacher
    â”‚   â”‚
    â”‚   â”œâ”€â†’ Step 3: LLM Generate
    â”‚   â”‚   â”œâ”€â†’ POST http://localhost:11434/api/generate
    â”‚   â”‚   â”œâ”€â†’ Prompt: "You are {teacher}. Explain {visibleText}..."
    â”‚   â”‚   â””â”€â†’ Response: Natural language explanation
    â”‚   â”‚
    â”‚   â”œâ”€â†’ Step 4: Map Language to Voice
    â”‚   â”‚   â””â”€â†’ Select TTS voice based on language
    â”‚   â”‚       (English â†’ en_US-lessac-medium, etc.)
    â”‚   â”‚
    â”‚   â”œâ”€â†’ Step 5: TTS Generate
    â”‚   â”‚   â”œâ”€â†’ POST http://localhost:8001/tts/generate
    â”‚   â”‚   â”œâ”€â†’ Input: text + voice
    â”‚   â”‚   â””â”€â†’ Output: audio.wav URL
    â”‚   â”‚
    â”‚   â”œâ”€â†’ Step 6: Video Generate
    â”‚   â”‚   â”œâ”€â†’ POST http://localhost:8003/generate
    â”‚   â”‚   â”œâ”€â†’ Input: audio URL + teacher avatar image
    â”‚   â”‚   â””â”€â†’ Output: video.mp4 URL
    â”‚   â”‚
    â”‚   â””â”€â†’ Step 7: Notify Coordinator
    â”‚       â”œâ”€â†’ POST /session/{id}/clip-ready
    â”‚       â””â”€â†’ Coordinator emits CLIP_READY event
    â”‚
    â””â”€â†’ Frontend receives SSE event
        â”œâ”€â†’ Auto-play video clip
        â””â”€â†’ Display captions
```

### Turn-Taking Logic

```
Initial State:
    Left Teacher:  IDLE
    Right Teacher: IDLE
    Turn: 0 (Left speaks first)

User Action â†’ Section Update
    â”‚
    â”œâ”€â†’ Coordinator: turn % 2 == 0 â†’ Left speaks
    â”‚   â”œâ”€â†’ Set speaker = "left"
    â”‚   â”œâ”€â†’ Set renderer = "right"
    â”‚   â””â”€â†’ Enqueue job for RIGHT (prepare next)
    â”‚
    â””â”€â†’ Coordinator: turn % 2 == 1 â†’ Right speaks
        â”œâ”€â†’ Set speaker = "right"
        â”œâ”€â†’ Set renderer = "left"
        â””â”€â†’ Enqueue job for LEFT (prepare next)

When Clip Finishes:
    â”‚
    â”œâ”€â†’ Frontend: POST /speech-ended
    â”‚
    â”œâ”€â†’ Coordinator: Increment turn
    â”‚
    â”œâ”€â†’ Coordinator: Swap speaker/renderer
    â”‚
    â””â”€â†’ Coordinator: If renderer has ready clip â†’ emit CLIP_READY
        â””â”€â†’ Frontend plays immediately (no delay!)
```

---

## ğŸ“ Project File Structure

```
Nextwork-Teachers-TechMonkey/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # This file - project overview
â”œâ”€â”€ ğŸ“„ README-AI.md                  # AI assistant documentation
â”œâ”€â”€ ğŸ“„ IMPLEMENTATION_PLAN.md       # Current implementation roadmap
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # Docker orchestration (optional)
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“‚ frontend/                    # Streamlit frontend application
â”‚   â”œâ”€â”€ app.py                      # Main UI application
â”‚   â”œâ”€â”€ requirements.txt            # Frontend dependencies
â”‚   â”œâ”€â”€ Dockerfile                  # Docker image (optional)
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ section_snapshot.js    # Browser extension for content capture
â”‚
â”œâ”€â”€ ğŸ“‚ services/                     # Microservices (FastAPI)
â”‚   â”œâ”€â”€ coordinator/                # Session state & turn-taking
â”‚   â”‚   â”œâ”€â”€ app.py                  # FastAPI application
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ tts/                        # Text-to-speech service
â”‚   â”‚   â”œâ”€â”€ app.py                  # Piper TTS API
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ animation/                  # Animation service (placeholder)
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â””â”€â”€ longcat_video/              # LongCat-Video service
â”‚       â”œâ”€â”€ app.py                  # Video generation API
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ“‚ n8n/                         # n8n workflow definitions
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ session-start-workflow.json    # Fast webhook for session creation
â”‚       â”œâ”€â”€ left-worker-workflow.json      # Left teacher pipeline
â”‚       â”œâ”€â”€ right-worker-workflow.json     # Right teacher pipeline
â”‚       â”œâ”€â”€ dual-teacher-workflow.json     # Legacy (5-teacher)
â”‚       â”œâ”€â”€ five-teacher-workflow.json     # Legacy (5-teacher)
â”‚       â””â”€â”€ README.md                      # Workflow documentation
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                      # Deployment & utility scripts
â”‚   â”œâ”€â”€ deploy_2teacher_system.sh   # Main deployment script
â”‚   â”œâ”€â”€ start_all_services.sh       # Start all services in tmux
â”‚   â”œâ”€â”€ install_prerequisites.sh    # Install Ollama, n8n, Mistral
â”‚   â”œâ”€â”€ setup_new_instance_with_storage.sh  # Complete Vast.ai setup
â”‚   â”œâ”€â”€ import_new_workflows.sh     # Import n8n workflows
â”‚   â”œâ”€â”€ check_complete_system.sh    # System health check
â”‚   â”œâ”€â”€ check_installations_and_disk_usage.sh  # Disk usage report
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ common.sh                # Shared functions & config
â”‚
â”œâ”€â”€ ğŸ“‚ configs/                      # Configuration files
â”‚   â”œâ”€â”€ llm_config.yaml              # LLM model settings
â”‚   â”œâ”€â”€ tts_config.yaml              # TTS voice settings
â”‚   â”œâ”€â”€ animation_config.yaml       # Animation quality settings
â”‚   â””â”€â”€ teacher_prompts.yaml         # Teacher personalities
â”‚
â”œâ”€â”€ ğŸ“‚ Nextwork-Teachers/           # Teacher avatar images
â”‚   â”œâ”€â”€ krishna.png
â”‚   â”œâ”€â”€ Maximus.png
â”‚   â”œâ”€â”€ Maya.png
â”‚   â”œâ”€â”€ Pano Bieber.png
â”‚   â””â”€â”€ TechMonkey Steve.png
â”‚
â”œâ”€â”€ ğŸ“‚ LongCat-Video/                # LongCat-Video submodule/project
â”‚   â”œâ”€â”€ weights/                     # Model weights
â”‚   â”œâ”€â”€ assets/                      # Assets
â”‚   â””â”€â”€ [LongCat-Video source code]
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                         # Documentation
â”‚   â”œâ”€â”€ QUICK_START_NEW_INSTANCE.md  # Setup guide for new Vast.ai instance
â”‚   â”œâ”€â”€ QUICK_START_2_TEACHER.md     # Quick start for 2-teacher system
â”‚   â”œâ”€â”€ TWO_TEACHER_ARCHITECTURE.md  # Architecture details
â”‚   â”œâ”€â”€ ARCHITECTURE.md              # System architecture
â”‚   â”œâ”€â”€ TERMINAL_GUIDE.md            # Desktop vs VAST terminal guide
â”‚   â””â”€â”€ [29 other documentation files]
â”‚
â””â”€â”€ ğŸ“‚ outputs/                      # Generated outputs (created at runtime)
    â””â”€â”€ longcat/                     # Generated video clips
```

---

## ğŸš€ Implementation Plan & Roadmap

### âœ… Phase 1: Core Infrastructure (COMPLETE)
- [x] Project structure
- [x] Coordinator API (session state, turn-taking)
- [x] n8n workflow orchestration
- [x] Frontend UI (Streamlit with dual video players)
- [x] Basic service deployment scripts

### âœ… Phase 2: LLM & TTS Integration (COMPLETE)
- [x] Ollama setup with Mistral 7B
- [x] LLM integration in n8n workflows
- [x] Piper TTS service
- [x] Language-to-voice mapping
- [x] Multi-language support

### âœ… Phase 3: Video Generation (COMPLETE)
- [x] LongCat-Video service integration
- [x] Video generation pipeline
- [x] Avatar image management
- [x] Clip notification system

### ğŸ”„ Phase 4: Database & Caching (IN PROGRESS)
- [x] PostgreSQL + pgvector setup
- [x] Vast.ai storage volume integration
- [ ] Database schema (sessions, sections, embeddings)
- [ ] Content-based caching (reuse videos for same content)
- [ ] RAG system for contextual retrieval

### ğŸ“‹ Phase 5: Page Segmentation & RAG (PLANNED)
- [ ] Automatic page segmentation service
- [ ] Pre-process all sections on page load
- [ ] Store embeddings in pgvector
- [ ] Retrieve relevant context for LLM prompts
- [ ] Round-robin section assignment to teachers

### ğŸ“‹ Phase 6: Polish & Optimization (PLANNED)
- [ ] Error handling & retry logic
- [ ] Performance optimization
- [ ] Caching strategy refinement
- [ ] Monitoring & logging
- [ ] Auto-scaling considerations

---

## ğŸ› ï¸ Tech Stack

### Core Technologies
- **Orchestration**: n8n (workflow automation)
- **LLM**: Ollama + Mistral 7B (local inference)
- **TTS**: Piper TTS (multi-language voices)
- **Video**: LongCat-Video (lip-sync animation)
- **Frontend**: Streamlit (Python web framework)
- **Backend**: FastAPI (Python async API)
- **Database**: PostgreSQL + pgvector (vector search)
- **Storage**: Vast.ai persistent volume

### Deployment
- **Hosting**: Vast.ai (GPU cloud instances)
- **GPUs**: 2x A100 (80GB VRAM total recommended)
- **Storage**: Vast.ai storage volume (200-500 GB)
- **Deployment Mode**: No-Docker (services run directly on host)

---

## ğŸš€ Quick Start

### Prerequisites
- Vast.ai account
- SSH access to Vast.ai instance
- PowerShell (for port forwarding on Windows)

### 1. Setup New Vast.ai Instance

**ğŸ“ VAST Terminal**

```bash
# Clone repository
cd ~
git clone https://github.com/SFitz911/Nextwork-Teachers-TechMonkey.git
cd Nextwork-Teachers-TechMonkey

# Run complete setup (includes Ollama, n8n, PostgreSQL, etc.)
bash scripts/setup_new_instance_with_storage.sh
```

### 2. Deploy Services

**ğŸ“ VAST Terminal**

```bash
cd ~/Nextwork-Teachers-TechMonkey

# Deploy all services (creates venv, installs dependencies, starts services)
bash scripts/deploy_2teacher_system.sh
```

### 3. Import n8n Workflows

**ğŸ“ VAST Terminal**

```bash
cd ~/Nextwork-Teachers-TechMonkey

# Import workflows (requires n8n API key in .env)
bash scripts/import_new_workflows.sh
```

### 4. Setup Port Forwarding

**ğŸ“ Desktop PowerShell**

```powershell
cd E:\DATA_1TB\Desktop\Nextwork_Teachers_TechMonkey
.\connect-vast.ps1
```

**Keep this window open!** Port forwarding stops if you close it.

### 5. Access Services

**ğŸ“ Desktop Browser**

- **Frontend**: http://localhost:8501
- **n8n**: http://localhost:5678
- **Coordinator API**: http://localhost:8004

---

## ğŸ“– Key Concepts

### Session State
Each student session has:
- **Session ID**: Unique identifier
- **Active Teachers**: Which two teachers are active (e.g., `["teacher_a", "teacher_d"]`)
- **Turn Counter**: Tracks whose turn it is to speak
- **Current Section**: What content the student is viewing
- **Queue Status**: Which teacher is rendering the next clip

### Turn-Taking
- **Round-robin**: Teachers alternate turns automatically
- **Parallel Processing**: While one speaks, the other prepares the next response
- **Zero Delay**: Next clip is ready before current one finishes

### Language Support
- **Multi-language**: Select language in UI (English, Spanish, French, etc.)
- **Voice Mapping**: Each language uses appropriate TTS voice
- **LLM Prompts**: LLM responds in selected language

---

## ğŸ”— Quick Links

- **GitHub**: https://github.com/SFitz911/Nextwork-Teachers-TechMonkey.git
- **Quick Start Guide**: [docs/QUICK_START_NEW_INSTANCE.md](docs/QUICK_START_NEW_INSTANCE.md)
- **Architecture Details**: [docs/TWO_TEACHER_ARCHITECTURE.md](docs/TWO_TEACHER_ARCHITECTURE.md)
- **Terminal Guide**: [docs/TERMINAL_GUIDE.md](docs/TERMINAL_GUIDE.md) (Desktop vs VAST Terminal)

---

## ğŸ“ Current Status

**âœ… Working:**
- Dual teacher system with turn-taking
- LLM generation (Mistral 7B via Ollama)
- TTS generation (Piper TTS, multi-language)
- Video generation (LongCat-Video)
- Frontend UI with real-time updates
- Session state management

**ğŸ”„ In Progress:**
- Database integration (PostgreSQL + pgvector)
- Content caching system
- Page segmentation & RAG

**ğŸ“‹ Planned:**
- Automatic page analysis
- Context-aware responses
- Performance optimization

---

## ğŸ¤ Contributing

This project is developed by Sean Fitzgerald. Contributions welcome!

## ğŸ“„ License

Open source - see LICENSE file for details.
